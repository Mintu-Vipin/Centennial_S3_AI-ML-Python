{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.5"
    },
    "colab": {
      "name": "MintuVipinJoy_COMP258Lab2_Ex1.ipynb",
      "provenance": [],
      "include_colab_link": true
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Mintu-Vipin/Semester3/blob/master/MintuVipinJoy_COMP258Lab2_Ex1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dkfLM94rQp_p"
      },
      "source": [
        "import os\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import json\n",
        "import matplotlib.pyplot as pl\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "%matplotlib inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HOdwOiUcQp_q"
      },
      "source": [
        "# function to compute the sigmoid\n",
        "sigmoid = lambda x: 1/(1 + np.exp(-x));\n",
        "#\n",
        "#function to comupute ReLU\n",
        "def relu(z):\n",
        "    return np.maximum(0,z)\n",
        "\n",
        "def relu_derivative(z):\n",
        "    return np.greater(z, 0).astype(int)\n",
        "\n",
        "def softmax(z):\n",
        "    z -= np.max(z)\n",
        "    sm - (np.exp(z).T / np.sum(np.exp(z), axis=0)).T\n",
        "    return sm\n",
        "\n",
        "def softmax_grad(softmax):\n",
        "    #Reshape the 1-d softwax to 2-d so that np.dot will do the matrix multiplication\n",
        "    s=softmax.reshape(-1,1)\n",
        "    return np.diagflat(s) - np.dot(s, s.T)   \n",
        "    \n",
        "################################################################################\n",
        "# This function implements the backpropagation algorithm for a simple 4-5-3 ANN\n",
        "#  W1 and W2 are the weight matrices of the respective layers:\n",
        "#   W1 is the weight matrix between the input layer and hidden layer\n",
        "#   W2 is the weight matrix between the hidden layer and output layer. \n",
        "#  X and D are the input and correct output of the training data (XOR), respectively.\n",
        "################################################################################\n",
        "def backprop(W1, W2, X, D):\n",
        "    alpha = 0.01; # learning rate\n",
        "    N=D.size;\n",
        "    for k in range(0,N):\n",
        "        x = X[k, :].T; #inputs from training data\n",
        "        #print(\"x=\",x)\n",
        "        d = D[k]; # correct output from training data\n",
        "        ##########################\n",
        "        # forward propagation step\n",
        "        ##########################\n",
        "        # calculate the weighted sum of hidden node\n",
        "        v1 = np.dot(W1,x);\n",
        "        #print(\"v1= \", v1)\n",
        "        #pass the weighted sum to the activation function, this gives the outputs from hidden layer\n",
        "        y1 = sigmoid(v1);\n",
        "        #print(\"y1= \", y1)\n",
        "        #calculate the weighted sum of the output layer\n",
        "        v = np.dot(W2,y1);\n",
        "        #print(\"v\", v)\n",
        "        # pass it to the activation function, this returns the output of the third layer\n",
        "        y = sigmoid(v);\n",
        "        #y=softmax(v)\n",
        "        #y=relu(v)\n",
        "        #print(\"y=\",y)\n",
        "        #calculate the error, difference between correct output and computed output\n",
        "        e = d - y;\n",
        "        #print(\"e= \",e)\n",
        "        #calculate delta, derivative of the activation function times the error\n",
        "        # note that ùúé‚Ä≤(ùë•)=ùúé(ùë•)‚àô(1‚àí ùúé(ùë•)) = y * (1-y)\n",
        "        delta = y*(1-y)*e; # element wise multiplication\n",
        "        #print(\"delta.shape= \",delta.shape)\n",
        "        #print(\"delta\", delta)\n",
        "        ###########################\n",
        "        # Backward propagation step\n",
        "        ###########################\n",
        "        # propagate the output node delta, Œ¥, backward, and calculate the deltas of the hidden layer.\n",
        "        e1 = np.dot(W2.T, delta);\n",
        "        #print(\"e1= \",e1)\n",
        "        delta1 = y1*(1-y1)*e1;  # element wise multiplication\n",
        "        #print(\"relu derivative: = \",relu_derivative(y1))\n",
        "        #relu_derivative =relu_derivative(y1)\n",
        "        #relu_derivative.shape=(1,5)\n",
        "        #delta1 = rlu_derivative*e1\n",
        "        #print(\"delta1=\",delta1)\n",
        "        # Adjust the weights according to the learning rule\n",
        "        #print(\"deta1.shape\",delta1.shape)\n",
        "        delta1.shape=(5,1) # column vector of deltas for the hidden layer\n",
        "        x.shape=(1,4) # row vector of the current input\n",
        "        dW1 = alpha*np.dot(delta1,x);\n",
        "        W1 = W1 + dW1;\n",
        "        #row vector of the hidden layer\n",
        "        y1.shape = (1,5)\n",
        "        delta.shape=(3,1)\n",
        "        #print(y1.T.shape)\n",
        "        dW2 = alpha*np.dot(delta,y1);\n",
        "        W2 = W2 + dW2;\n",
        "    #\n",
        "    return W1, W2;\n",
        "#"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cKfnHHMYQp_s",
        "outputId": "cab25cad-b62e-47ae-f5a9-3a420d4d47cd"
      },
      "source": [
        "# Training data\n",
        "\n",
        "# Load the training data(Iris data)\n",
        "iris_training = pd.read_json('training.json')\n",
        "iris_training = pd.DataFrame(iris_training)\n",
        "print(\"Iris training data\\n-------------------\\n\",iris_training.head())\n",
        "print(\"\\n\\nLength:  \",len(iris_training))\n",
        "print(\"\\n\\nShape:   \",iris_training.shape)\n",
        "print(\"\\n\\nInfo:\\n   \",iris_training.info)\n",
        "print(\"\\n\\nDescribe:\\n   \",iris_training.describe())\n",
        "print(\"\\n\\nHow many in each species:\\n\", iris_training['species'].value_counts())\n",
        "\n",
        "# Extract output column\n",
        "iris_y=iris_training['species']\n",
        "print(\"\\niris_y\\n\", iris_y)\n",
        "en = LabelEncoder()\n",
        "iris_y = en.fit_transform(iris_y)\n",
        "# iris_y=np.array (iris_y.to_numpy ())\n",
        "print(\"\\niris_y\\n\",iris_y)\n",
        "D=iris_y\n",
        "\n",
        "# Input array\n",
        "\n",
        "# Drop the class 'species'\n",
        "iris_training.drop(['species'], axis = 1, inplace=True)\n",
        "print (iris_training.head ())\n",
        "iris_X=np.array(iris_training.to_numpy())\n",
        "print(\"\\niris_X\\n\",iris_X)\n",
        "X=iris_X\n",
        "\n",
        "\n",
        "\n",
        "# Testing data\n",
        "\n",
        "# Load the testing data\n",
        "iris_testing = pd.read_json('test.json')\n",
        "iris_testing = pd.DataFrame(iris_testing)\n",
        "print(\"Iris Testing data\\n-------------------\\n\",iris_testing.head())\n",
        "print(\"\\n\\nLength:  \",len(iris_testing))\n",
        "print(\"\\n\\nShape:   \",iris_testing.shape)\n",
        "print(\"\\n\\nInfo:\\n   \",iris_testing.info)\n",
        "print(\"\\n\\nDescribe:\\n   \",iris_testing.describe())\n",
        "print(\"\\n\\nHow many in each species:\\n\", iris_testing['species'].value_counts())\n",
        "\n",
        "\n",
        "# Extract output column\n",
        "iris_y_test=iris_testing['species']\n",
        "print(\"\\niris_y_test\\n\", iris_y_test)\n",
        "\n",
        "# Input array\n",
        "\n",
        "# Drop the class 'species'\n",
        "iris_testing.drop(['species'], axis = 1, inplace=True)\n",
        "print (iris_testing.head ())\n",
        "iris_X_testing=np.array(iris_testing.to_numpy())\n",
        "print(\"\\niris_X_testing\\n\",iris_X_testing)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Iris training data\n",
            "-------------------\n",
            "    sepal_length  sepal_width  petal_length  petal_width species\n",
            "0           5.1          3.5           1.4          0.2  setosa\n",
            "1           4.9          3.0           1.4          0.2  setosa\n",
            "2           4.7          3.2           1.3          0.2  setosa\n",
            "3           4.6          3.1           1.5          0.2  setosa\n",
            "4           5.0          3.6           1.4          0.2  setosa\n",
            "\n",
            "\n",
            "Length:   147\n",
            "\n",
            "\n",
            "Shape:    (147, 5)\n",
            "\n",
            "\n",
            "Info:\n",
            "    <bound method DataFrame.info of      sepal_length  sepal_width  petal_length  petal_width    species\n",
            "0             5.1          3.5           1.4          0.2     setosa\n",
            "1             4.9          3.0           1.4          0.2     setosa\n",
            "2             4.7          3.2           1.3          0.2     setosa\n",
            "3             4.6          3.1           1.5          0.2     setosa\n",
            "4             5.0          3.6           1.4          0.2     setosa\n",
            "..            ...          ...           ...          ...        ...\n",
            "142           6.7          3.3           5.7          2.5  virginica\n",
            "143           6.7          3.0           5.2          2.3  virginica\n",
            "144           6.3          2.5           5.0          1.9  virginica\n",
            "145           6.5          3.0           5.2          2.0  virginica\n",
            "146           6.2          3.4           5.4          2.3  virginica\n",
            "\n",
            "[147 rows x 5 columns]>\n",
            "\n",
            "\n",
            "Describe:\n",
            "           sepal_length  sepal_width  petal_length  petal_width\n",
            "count    147.000000   147.000000    147.000000   147.000000\n",
            "mean       5.846939     3.049660      3.760544     1.199320\n",
            "std        0.835620     0.432162      1.770441     0.766463\n",
            "min        4.300000     2.000000      1.000000     0.100000\n",
            "25%        5.100000     2.800000      1.550000     0.300000\n",
            "50%        5.800000     3.000000      4.400000     1.300000\n",
            "75%        6.400000     3.300000      5.100000     1.800000\n",
            "max        7.900000     4.400000      6.900000     2.500000\n",
            "\n",
            "\n",
            "How many in each species:\n",
            " versicolor    49\n",
            "virginica     49\n",
            "setosa        49\n",
            "Name: species, dtype: int64\n",
            "\n",
            "iris_y\n",
            " 0         setosa\n",
            "1         setosa\n",
            "2         setosa\n",
            "3         setosa\n",
            "4         setosa\n",
            "         ...    \n",
            "142    virginica\n",
            "143    virginica\n",
            "144    virginica\n",
            "145    virginica\n",
            "146    virginica\n",
            "Name: species, Length: 147, dtype: object\n",
            "\n",
            "iris_y\n",
            " [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
            " 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
            " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
            " 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2]\n",
            "   sepal_length  sepal_width  petal_length  petal_width\n",
            "0           5.1          3.5           1.4          0.2\n",
            "1           4.9          3.0           1.4          0.2\n",
            "2           4.7          3.2           1.3          0.2\n",
            "3           4.6          3.1           1.5          0.2\n",
            "4           5.0          3.6           1.4          0.2\n",
            "\n",
            "iris_X\n",
            " [[5.1 3.5 1.4 0.2]\n",
            " [4.9 3.  1.4 0.2]\n",
            " [4.7 3.2 1.3 0.2]\n",
            " [4.6 3.1 1.5 0.2]\n",
            " [5.  3.6 1.4 0.2]\n",
            " [4.6 3.4 1.4 0.3]\n",
            " [5.  3.4 1.5 0.2]\n",
            " [4.4 2.9 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.4 3.7 1.5 0.2]\n",
            " [4.8 3.4 1.6 0.2]\n",
            " [4.8 3.  1.4 0.1]\n",
            " [4.3 3.  1.1 0.1]\n",
            " [5.8 4.  1.2 0.2]\n",
            " [5.7 4.4 1.5 0.4]\n",
            " [5.4 3.9 1.3 0.4]\n",
            " [5.1 3.5 1.4 0.3]\n",
            " [5.7 3.8 1.7 0.3]\n",
            " [5.1 3.8 1.5 0.3]\n",
            " [5.4 3.4 1.7 0.2]\n",
            " [5.1 3.7 1.5 0.4]\n",
            " [4.6 3.6 1.  0.2]\n",
            " [5.1 3.3 1.7 0.5]\n",
            " [4.8 3.4 1.9 0.2]\n",
            " [5.  3.  1.6 0.2]\n",
            " [5.  3.4 1.6 0.4]\n",
            " [5.2 3.5 1.5 0.2]\n",
            " [5.2 3.4 1.4 0.2]\n",
            " [4.7 3.2 1.6 0.2]\n",
            " [4.8 3.1 1.6 0.2]\n",
            " [5.4 3.4 1.5 0.4]\n",
            " [5.2 4.1 1.5 0.1]\n",
            " [5.5 4.2 1.4 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [5.  3.2 1.2 0.2]\n",
            " [5.5 3.5 1.3 0.2]\n",
            " [4.9 3.1 1.5 0.1]\n",
            " [4.4 3.  1.3 0.2]\n",
            " [5.1 3.4 1.5 0.2]\n",
            " [5.  3.5 1.3 0.3]\n",
            " [4.5 2.3 1.3 0.3]\n",
            " [4.4 3.2 1.3 0.2]\n",
            " [5.  3.5 1.6 0.6]\n",
            " [5.1 3.8 1.9 0.4]\n",
            " [4.8 3.  1.4 0.3]\n",
            " [5.1 3.8 1.6 0.2]\n",
            " [4.6 3.2 1.4 0.2]\n",
            " [5.3 3.7 1.5 0.2]\n",
            " [5.  3.3 1.4 0.2]\n",
            " [7.  3.2 4.7 1.4]\n",
            " [6.4 3.2 4.5 1.5]\n",
            " [6.9 3.1 4.9 1.5]\n",
            " [5.5 2.3 4.  1.3]\n",
            " [6.5 2.8 4.6 1.5]\n",
            " [5.7 2.8 4.5 1.3]\n",
            " [6.3 3.3 4.7 1.6]\n",
            " [4.9 2.4 3.3 1. ]\n",
            " [6.6 2.9 4.6 1.3]\n",
            " [5.2 2.7 3.9 1.4]\n",
            " [5.  2.  3.5 1. ]\n",
            " [5.9 3.  4.2 1.5]\n",
            " [6.  2.2 4.  1. ]\n",
            " [6.1 2.9 4.7 1.4]\n",
            " [5.6 2.9 3.6 1.3]\n",
            " [6.7 3.1 4.4 1.4]\n",
            " [5.6 3.  4.5 1.5]\n",
            " [5.8 2.7 4.1 1. ]\n",
            " [6.2 2.2 4.5 1.5]\n",
            " [5.6 2.5 3.9 1.1]\n",
            " [5.9 3.2 4.8 1.8]\n",
            " [6.1 2.8 4.  1.3]\n",
            " [6.3 2.5 4.9 1.5]\n",
            " [6.1 2.8 4.7 1.2]\n",
            " [6.4 2.9 4.3 1.3]\n",
            " [6.6 3.  4.4 1.4]\n",
            " [6.8 2.8 4.8 1.4]\n",
            " [6.7 3.  5.  1.7]\n",
            " [6.  2.9 4.5 1.5]\n",
            " [5.7 2.6 3.5 1. ]\n",
            " [5.5 2.4 3.8 1.1]\n",
            " [5.5 2.4 3.7 1. ]\n",
            " [5.8 2.7 3.9 1.2]\n",
            " [6.  2.7 5.1 1.6]\n",
            " [5.4 3.  4.5 1.5]\n",
            " [6.  3.4 4.5 1.6]\n",
            " [6.7 3.1 4.7 1.5]\n",
            " [6.3 2.3 4.4 1.3]\n",
            " [5.6 3.  4.1 1.3]\n",
            " [5.5 2.5 4.  1.3]\n",
            " [5.5 2.6 4.4 1.2]\n",
            " [6.1 3.  4.6 1.4]\n",
            " [5.8 2.6 4.  1.2]\n",
            " [5.  2.3 3.3 1. ]\n",
            " [5.6 2.7 4.2 1.3]\n",
            " [5.7 3.  4.2 1.2]\n",
            " [6.2 2.9 4.3 1.3]\n",
            " [5.1 2.5 3.  1.1]\n",
            " [5.7 2.8 4.1 1.3]\n",
            " [6.3 3.3 6.  2.5]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [7.1 3.  5.9 2.1]\n",
            " [6.3 2.9 5.6 1.8]\n",
            " [6.5 3.  5.8 2.2]\n",
            " [7.6 3.  6.6 2.1]\n",
            " [4.9 2.5 4.5 1.7]\n",
            " [7.3 2.9 6.3 1.8]\n",
            " [6.7 2.5 5.8 1.8]\n",
            " [7.2 3.6 6.1 2.5]\n",
            " [6.5 3.2 5.1 2. ]\n",
            " [6.4 2.7 5.3 1.9]\n",
            " [6.8 3.  5.5 2.1]\n",
            " [5.7 2.5 5.  2. ]\n",
            " [5.8 2.8 5.1 2.4]\n",
            " [6.4 3.2 5.3 2.3]\n",
            " [6.5 3.  5.5 1.8]\n",
            " [7.7 3.8 6.7 2.2]\n",
            " [7.7 2.6 6.9 2.3]\n",
            " [6.  2.2 5.  1.5]\n",
            " [6.9 3.2 5.7 2.3]\n",
            " [5.6 2.8 4.9 2. ]\n",
            " [7.7 2.8 6.7 2. ]\n",
            " [6.3 2.7 4.9 1.8]\n",
            " [6.7 3.3 5.7 2.1]\n",
            " [7.2 3.2 6.  1.8]\n",
            " [6.2 2.8 4.8 1.8]\n",
            " [6.1 3.  4.9 1.8]\n",
            " [6.4 2.8 5.6 2.1]\n",
            " [7.2 3.  5.8 1.6]\n",
            " [7.4 2.8 6.1 1.9]\n",
            " [7.9 3.8 6.4 2. ]\n",
            " [6.4 2.8 5.6 2.2]\n",
            " [6.3 2.8 5.1 1.5]\n",
            " [6.1 2.6 5.6 1.4]\n",
            " [7.7 3.  6.1 2.3]\n",
            " [6.3 3.4 5.6 2.4]\n",
            " [6.4 3.1 5.5 1.8]\n",
            " [6.  3.  4.8 1.8]\n",
            " [6.9 3.1 5.4 2.1]\n",
            " [6.7 3.1 5.6 2.4]\n",
            " [6.9 3.1 5.1 2.3]\n",
            " [5.8 2.7 5.1 1.9]\n",
            " [6.8 3.2 5.9 2.3]\n",
            " [6.7 3.3 5.7 2.5]\n",
            " [6.7 3.  5.2 2.3]\n",
            " [6.3 2.5 5.  1.9]\n",
            " [6.5 3.  5.2 2. ]\n",
            " [6.2 3.4 5.4 2.3]]\n",
            "Iris Testing data\n",
            "-------------------\n",
            "    sepal_length  sepal_width  petal_length  petal_width     species\n",
            "0           5.4          3.9           1.7          0.4      setosa\n",
            "1           5.9          3.0           5.1          1.8   virginica\n",
            "2           5.7          2.9           4.2          1.3  versicolor\n",
            "\n",
            "\n",
            "Length:   3\n",
            "\n",
            "\n",
            "Shape:    (3, 5)\n",
            "\n",
            "\n",
            "Info:\n",
            "    <bound method DataFrame.info of    sepal_length  sepal_width  petal_length  petal_width     species\n",
            "0           5.4          3.9           1.7          0.4      setosa\n",
            "1           5.9          3.0           5.1          1.8   virginica\n",
            "2           5.7          2.9           4.2          1.3  versicolor>\n",
            "\n",
            "\n",
            "Describe:\n",
            "           sepal_length  sepal_width  petal_length  petal_width\n",
            "count      3.000000     3.000000      3.000000     3.000000\n",
            "mean       5.666667     3.266667      3.666667     1.166667\n",
            "std        0.251661     0.550757      1.761628     0.709460\n",
            "min        5.400000     2.900000      1.700000     0.400000\n",
            "25%        5.550000     2.950000      2.950000     0.850000\n",
            "50%        5.700000     3.000000      4.200000     1.300000\n",
            "75%        5.800000     3.450000      4.650000     1.550000\n",
            "max        5.900000     3.900000      5.100000     1.800000\n",
            "\n",
            "\n",
            "How many in each species:\n",
            " virginica     1\n",
            "versicolor    1\n",
            "setosa        1\n",
            "Name: species, dtype: int64\n",
            "\n",
            "iris_y_test\n",
            " 0        setosa\n",
            "1     virginica\n",
            "2    versicolor\n",
            "Name: species, dtype: object\n",
            "   sepal_length  sepal_width  petal_length  petal_width\n",
            "0           5.4          3.9           1.7          0.4\n",
            "1           5.9          3.0           5.1          1.8\n",
            "2           5.7          2.9           4.2          1.3\n",
            "\n",
            "iris_X_testing\n",
            " [[5.4 3.9 1.7 0.4]\n",
            " [5.9 3.  5.1 1.8]\n",
            " [5.7 2.9 4.2 1.3]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_D5gyddKQp_t",
        "outputId": "dcbbe879-8476-44d0-9d58-246be8b96368"
      },
      "source": [
        "# initialize the weights between input layer and hidden layer\n",
        "W1 = 2*np.random.rand(5, 4) - 1;\n",
        "\n",
        "# initialize the weights between hidden layer and output layer\n",
        "W2 = 2*np.random.rand(3, 5) - 1;\n",
        "\n",
        "print(\"-----------------Before Updating weights:----------------\")\n",
        "print('Weight between input layer and hidden layer(W1) = \\n', W1)\n",
        "print('\\nWeight between hidden layer and output layer(W2)= \\n', W2)\n",
        "\n",
        "\n",
        "# run the backprop algorithm to compute the weights\n",
        "for epoch in range(1,10000): # train\n",
        "    W1, W2 = backprop(W1, W2, X, D);\n",
        "    \n",
        "print(\"-----------------After Updating weights:----------------\")\n",
        "print('Weight between input layer and hidden layer(W1) = \\n', W1)\n",
        "print('\\nWeight between hidden layer and output layer(W2)= \\n', W2)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "-----------------Before Updating weights:----------------\n",
            "Weight between input layer and hidden layer(W1) = \n",
            " [[-0.46871259  0.5995747   0.89548925  0.6814567 ]\n",
            " [ 0.66273405 -0.41258658  0.6257586  -0.60412873]\n",
            " [ 0.66406584 -0.77245103 -0.73540303  0.57390335]\n",
            " [ 0.2393468   0.1511916  -0.43077991  0.32699648]\n",
            " [-0.10358895  0.64504522 -0.32913563 -0.50852886]]\n",
            "\n",
            "Weight between hidden layer and output layer(W2)= \n",
            " [[ 0.27123308 -0.21299639 -0.15196204  0.19933963 -0.07841094]\n",
            " [ 0.29156355  0.76924601  0.03282275 -0.5973265  -0.78628635]\n",
            " [ 0.72060174  0.76464562 -0.5224536  -0.0511038  -0.09631703]]\n",
            "-----------------After Updating weights:----------------\n",
            "Weight between input layer and hidden layer(W1) = \n",
            " [[-1.17231041 -0.67979093  2.3444527   1.42461296]\n",
            " [-0.30203625 -1.83296815  2.28849068  0.3206024 ]\n",
            " [ 1.08655497  0.21057655 -2.16650608 -0.16837023]\n",
            " [ 0.50451979  0.91713214 -1.77664319 -0.36147265]\n",
            " [ 0.28625415  1.50394594 -1.67447544 -1.18552081]]\n",
            "\n",
            "Weight between hidden layer and output layer(W2)= \n",
            " [[ 5.03836624  4.24255212 -1.68570701 -1.38815189 -2.44368026]\n",
            " [ 4.52739425  4.75358711 -1.13854538 -1.81800252 -2.56171348]\n",
            " [ 4.77245821  4.51355906 -1.88061976 -1.51289737 -2.14149163]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "av3X_L5GQp_t",
        "outputId": "a39f36f1-122b-4cf9-bbea-13861da21e93"
      },
      "source": [
        "# Training\n",
        "\n",
        "# calculate the output of the network with computed weights \n",
        "N = 147\n",
        "for k in range(0,N):\n",
        "    x = X[k, :].T; #inputs from training data\n",
        "    \n",
        "    ##########################\n",
        "    # forward propagation step\n",
        "    ##########################\n",
        "    # calculate the weighted sum of hidden node\n",
        "    v1 = np.dot(W1,x);\n",
        "    #print(\"v1= \", v1)\n",
        "    #pass the weighted sum to the activation function, this gives the outputs from hidden layer\n",
        "    y1 = sigmoid(v1);\n",
        "    #print(\"y1= \", y1)\n",
        "    #calculate the weighted sum of the output layer\n",
        "    v = np.dot(W2,y1);\n",
        "    #print(\"v\", v)\n",
        "    # pass it to the activation function, this returns the output of the third layer\n",
        "    y = sigmoid(v);\n",
        "    print(\"y =\",y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y = [0.00506321 0.00504735 0.00501515]\n",
            "y = [0.006184   0.00622891 0.00614186]\n",
            "y = [0.00559123 0.0055741  0.00554818]\n",
            "y = [0.00717424 0.00712707 0.00716585]\n",
            "y = [0.00504291 0.00500926 0.00499778]\n",
            "y = [0.00591761 0.00583804 0.00588334]\n",
            "y = [0.0056074  0.00558274 0.00557067]\n",
            "y = [0.00774925 0.00772751 0.0077406 ]\n",
            "y = [0.00628203 0.00630032 0.00625934]\n",
            "y = [0.00486159 0.0048473  0.00481163]\n",
            "y = [0.00642376 0.00634009 0.00641271]\n",
            "y = [0.00618568 0.00621567 0.0061557 ]\n",
            "y = [0.00558651 0.00556435 0.00554616]\n",
            "y = [0.00425508 0.00425186 0.00419173]\n",
            "y = [0.00441473 0.00438863 0.00435709]\n",
            "y = [0.00452726 0.00451246 0.00446683]\n",
            "y = [0.00514042 0.0051242  0.00508887]\n",
            "y = [0.00503097 0.00502027 0.00498185]\n",
            "y = [0.00506771 0.00501715 0.00502334]\n",
            "y = [0.00587888 0.00589377 0.00584566]\n",
            "y = [0.00526061 0.0052147  0.00521217]\n",
            "y = [0.00459782 0.00456921 0.00454251]\n",
            "y = [0.00747583 0.00745994 0.0074286 ]\n",
            "y = [0.00937206 0.00911178 0.00946922]\n",
            "y = [0.00733723 0.00741577 0.00731974]\n",
            "y = [0.00638762 0.0063439  0.00634813]\n",
            "y = [0.00523291 0.00521958 0.00518851]\n",
            "y = [0.00509397 0.00509612 0.00504305]\n",
            "y = [0.00733506 0.00726405 0.00733837]\n",
            "y = [0.00745763 0.00744949 0.0074545 ]\n",
            "y = [0.00536649 0.00538445 0.00530702]\n",
            "y = [0.00466913 0.00461929 0.00462505]\n",
            "y = [0.00441096 0.00438712 0.00435506]\n",
            "y = [0.00628203 0.00630032 0.00625934]\n",
            "y = [0.00500866 0.00502147 0.00495161]\n",
            "y = [0.00463662 0.00464596 0.00457669]\n",
            "y = [0.00628203 0.00630032 0.00625934]\n",
            "y = [0.00655889 0.00652577 0.00653004]\n",
            "y = [0.00548392 0.00547207 0.00544313]\n",
            "y = [0.00498549 0.00496762 0.00493141]\n",
            "y = [0.01110103 0.01159674 0.01104026]\n",
            "y = [0.00604548 0.00597713 0.00601609]\n",
            "y = [0.00653249 0.00646087 0.00647459]\n",
            "y = [0.00700285 0.00681057 0.00700554]\n",
            "y = [0.00655895 0.00659313 0.00651214]\n",
            "y = [0.00525213 0.00518633 0.00521895]\n",
            "y = [0.00619622 0.00614857 0.00616876]\n",
            "y = [0.00493139 0.00490924 0.00488395]\n",
            "y = [0.00542024 0.00541715 0.00537485]\n",
            "y = [0.99975994 0.99976681 0.99976002]\n",
            "y = [0.99977934 0.99977972 0.99977865]\n",
            "y = [0.99984662 0.99984878 0.99984663]\n",
            "y = [0.9998273  0.99983071 0.99982674]\n",
            "y = [0.99984339 0.99984629 0.99984299]\n",
            "y = [0.99985818 0.99985787 0.99985863]\n",
            "y = [0.99983657 0.9998351  0.99983638]\n",
            "y = [0.99918999 0.99920563 0.99918982]\n",
            "y = [0.99980996 0.99981453 0.99981028]\n",
            "y = [0.99978329 0.99978093 0.99978211]\n",
            "y = [0.99971659 0.9997284  0.99971634]\n",
            "y = [0.99976571 0.99976478 0.99976418]\n",
            "y = [0.99973257 0.99975    0.9997333 ]\n",
            "y = [0.99986415 0.99986435 0.99986446]\n",
            "y = [0.99890061 0.99890268 0.99888407]\n",
            "y = [0.99967233 0.99968349 0.99967121]\n",
            "y = [0.99985782 0.99985621 0.99985795]\n",
            "y = [0.99970872 0.9997151  0.99971145]\n",
            "y = [0.99987339 0.99987611 0.99987305]\n",
            "y = [0.99971256 0.99972072 0.99971311]\n",
            "y = [0.99987635 0.99987512 0.99987634]\n",
            "y = [0.99959158 0.99960689 0.99958939]\n",
            "y = [0.99988778 0.99988864 0.99988795]\n",
            "y = [0.9998611  0.9998618  0.99986177]\n",
            "y = [0.99971562 0.99972474 0.99971539]\n",
            "y = [0.99972781 0.99973637 0.99972687]\n",
            "y = [0.99985092 0.99985426 0.99985094]\n",
            "y = [0.99987711 0.99987787 0.99987707]\n",
            "y = [0.99984794 0.99984809 0.99984778]\n",
            "y = [0.99822156 0.99836492 0.99823416]\n",
            "y = [0.99970095 0.99971098 0.99970103]\n",
            "y = [0.99957152 0.99959157 0.99957339]\n",
            "y = [0.99960819 0.99961961 0.99960756]\n",
            "y = [0.99989588 0.9998959  0.99989622]\n",
            "y = [0.9998643  0.99986242 0.99986453]\n",
            "y = [0.99979669 0.99979131 0.99979595]\n",
            "y = [0.99982237 0.99982483 0.99982209]\n",
            "y = [0.99984447 0.99984975 0.99984413]\n",
            "y = [0.99972799 0.99972367 0.99972786]\n",
            "y = [0.99980441 0.99980684 0.99980386]\n",
            "y = [0.99986162 0.99986169 0.99986215]\n",
            "y = [0.99984485 0.99984478 0.99984511]\n",
            "y = [0.9997252  0.99973285 0.99972499]\n",
            "y = [0.99923423 0.99926584 0.9992335 ]\n",
            "y = [0.99982201 0.9998224  0.99982205]\n",
            "y = [0.99974436 0.99974177 0.99974548]\n",
            "y = [0.99975429 0.99975877 0.99975426]\n",
            "y = [0.9943718  0.99465641 0.99427301]\n",
            "y = [0.99976362 0.99976445 0.99976329]\n",
            "y = [0.99990461 0.99990449 0.99990501]\n",
            "y = [0.9998991  0.99989902 0.99989939]\n",
            "y = [0.9999025  0.99990261 0.99990284]\n",
            "y = [0.99990179 0.99990174 0.99990219]\n",
            "y = [0.99990356 0.99990352 0.99990393]\n",
            "y = [0.99990534 0.99990539 0.99990576]\n",
            "y = [0.99989287 0.99989239 0.99989309]\n",
            "y = [0.99990438 0.99990445 0.9999048 ]\n",
            "y = [0.99990374 0.99990388 0.99990413]\n",
            "y = [0.9999025  0.99990239 0.99990283]\n",
            "y = [0.99988662 0.99988641 0.99988659]\n",
            "y = [0.99989904 0.99989922 0.9998993 ]\n",
            "y = [0.99989881 0.99989895 0.99989904]\n",
            "y = [0.99990001 0.99990004 0.99990026]\n",
            "y = [0.99990045 0.99990034 0.99990066]\n",
            "y = [0.99989675 0.99989653 0.99989689]\n",
            "y = [0.99989894 0.99989891 0.99989929]\n",
            "y = [0.99990423 0.99990416 0.99990467]\n",
            "y = [0.99990625 0.99990629 0.99990669]\n",
            "y = [0.99989774 0.99989817 0.99989803]\n",
            "y = [0.99990076 0.99990076 0.99990102]\n",
            "y = [0.99989603 0.99989574 0.99989622]\n",
            "y = [0.99990563 0.9999057  0.99990607]\n",
            "y = [0.99988843 0.99988896 0.99988843]\n",
            "y = [0.99990017 0.99990002 0.9999005 ]\n",
            "y = [0.99990126 0.9999013  0.99990166]\n",
            "y = [0.99988323 0.9998836  0.99988314]\n",
            "y = [0.99988503 0.99988475 0.99988509]\n",
            "y = [0.9999028  0.99990282 0.99990315]\n",
            "y = [0.99989866 0.99989891 0.99989905]\n",
            "y = [0.99990337 0.99990356 0.99990374]\n",
            "y = [0.99990055 0.99990049 0.99990095]\n",
            "y = [0.99990303 0.99990306 0.99990337]\n",
            "y = [0.99989043 0.99989064 0.99989077]\n",
            "y = [0.99990249 0.99990249 0.99990295]\n",
            "y = [0.99990279 0.99990305 0.99990309]\n",
            "y = [0.99990086 0.99990056 0.99990116]\n",
            "y = [0.99989864 0.99989849 0.99989901]\n",
            "y = [0.99988138 0.99988096 0.99988137]\n",
            "y = [0.99989504 0.99989526 0.99989515]\n",
            "y = [0.99990126 0.99990126 0.99990151]\n",
            "y = [0.99988671 0.99988731 0.99988634]\n",
            "y = [0.9998991  0.99989902 0.99989939]\n",
            "y = [0.99990308 0.99990304 0.99990344]\n",
            "y = [0.99990159 0.99990148 0.99990186]\n",
            "y = [0.99989429 0.99989456 0.99989424]\n",
            "y = [0.99989539 0.99989591 0.99989548]\n",
            "y = [0.99989377 0.99989384 0.99989389]\n",
            "y = [0.99989775 0.99989727 0.99989798]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JfakfaQTQp_u",
        "outputId": "d3c0defe-83b5-4e4b-f746-d81fd56a6679"
      },
      "source": [
        "#Testing\n",
        "\n",
        "# calculate the output of the network with computed weights \n",
        "N = 3\n",
        "for k in range(0,N):\n",
        "    x = iris_X_testing[k, :].T; #inputs from training data\n",
        "    \n",
        "    ##########################\n",
        "    # forward propagation step\n",
        "    ##########################\n",
        "    # calculate the weighted sum of hidden node\n",
        "    v1 = np.dot(W1,x);\n",
        "    #print(\"v1= \", v1)\n",
        "    #pass the weighted sum to the activation function, this gives the outputs from hidden layer\n",
        "    y1 = sigmoid(v1);\n",
        "    #print(\"y1= \", y1)\n",
        "    #calculate the weighted sum of the output layer\n",
        "    v = np.dot(W2,y1);\n",
        "    #print(\"v\", v)\n",
        "    # pass it to the activation function, this returns the output of the third layer\n",
        "    y = sigmoid(v);\n",
        "    print(\"y =\",y)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "y = [0.0052765  0.00522372 0.00523317]\n",
            "y = [0.99989454 0.99989417 0.99989483]\n",
            "y = [0.99978294 0.99978199 0.99978304]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RPKM-w8zQp_u"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}